{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaiyoyume/zerodeeplearning_2/blob/main/%EF%BC%93%E7%AB%A0%E3%80%80word2vec.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdslwoyFEujX"
      },
      "source": [
        "#3章　word2vec\n",
        "単語の分散表現・・・単語を密な固定長ベクトルに変換したもの。\n",
        "\n",
        "「推論ベースの手法」によって、**単語の分散表現**を得たい。  \n",
        "「推論ベースの手法」は、推論する手法で、その推論にはニューラルネットワークが使える。    \n",
        "推論ベースの手法のひとつに、word2vecがある。  \n",
        "word2vecは、シンプルな２層のニューラルネットワークで構成されている。  \n",
        "この章では、処理効率は低いが分かりすい\"シンプルな\"word2vecを実装する。  \n",
        "大きなデータセットは扱えないが、小さなデータセットなら問題なく処理できる。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSGSNGtr-nUZ"
      },
      "source": [
        "## 3.1　推論ベースの手法とニューラルネットワーク"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p0tVn47eWSuP"
      },
      "source": [
        "###3.1.1 カウントベースの手法の問題点  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GlvNW89xd0jT"
      },
      "source": [
        "前章のカウントベースの手法では、学習データを一度にまとめて処理していた。  \n",
        "それに対して、推論ベースの手法では、学習データの一部を使って、逐次的に学習する。  \n",
        "\n",
        "これが意味することは、語彙数が大きいコーパスにおいてSVDなどの計算量が膨大で処理が難しい場合でも、ニューラルネットワークではデータを小分けにして学習できる。  \n",
        "\n",
        "さらに、ニューラルネットワークの学習は複数マシン/複数GPUに利用による並列計算も可能であり、全体の学習も高速化できる。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ec5S-wvqW3a0"
      },
      "source": [
        "###3.1.2 推論ベースの手法の概要\n",
        "推論ベースの手法では「推論」することが主な作業になる。  \n",
        "これは、図3-2で示すように、周囲の単語（コンテキスト）が与えられたときに、「？」にどのような単語が出現するのかを推測する作業である。\n",
        "\n",
        "「**you** ? **goodbye** and I say hello.」\n",
        "\n",
        "こののような推論問題を解くこと、そして、学習することが「推論ベースの手法」の扱う問題である。  \n",
        "このような問題を繰り返し解くことで、単語の出現パターンを学習する。\n",
        "\n",
        "推論ベースの手法では、何らかのモデルが登場する。  \n",
        "私たちは、そのモデルにニューラルネットワークを使う。  \n",
        "モデルはコンテキスト情報を入力として受け取り、（出現しうるであろう）各単語の出現する確率を出力する。  \n",
        "そのような枠組みの中で、正しい推測ができるように、コーパスを使ってモデルの学習を行う。  \n",
        "そして、その学習結果として、単語の分散表現を得られるというのが推論ベースの手法の全体図になる。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XNdos01Wf3TG"
      },
      "source": [
        "###3.1.3 ニューラルネットワークにおける単語の処理方法\n",
        "これから、ニューラルネットワークを使って「単語」を処理する。  \n",
        "ニューラルネットワークは\"you”や\"say\"などの単語を、そのままでは処理できないので、単語を「固定長のベクトル」に変換する必要がある。\n",
        "\n",
        "そのための方法のひとつは、単語を**one-hot表現**（または**one-hotベクトル**）で変換することである。  \n",
        "one-hot表現とは、ベクトルの要素の中でひとつだけが１で、残りはすべて０であるようなベクトルを言う。  \n",
        "\n",
        "例えば、「You say goodbye and I say hello.」という1文をコーパスとして扱うと、コーパスには語彙が全部で７個存在する。（\"you\",　\"say\",　\"goodbye\",　\"and\",　\"I\",　\"hello\",　\".\"）  \n",
        "このとき各単語は下の表のようにone-hot表現へ変換することができる。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![image.png](data:image/png;base64,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)"
      ],
      "metadata": {
        "id": "3Ndb0-nwLiId"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "このように単語を固定長のベクトルに変換してしまえば、ニューラルネットワークの入力層はニューロンの数を\"固定\"することができる。\n",
        "\n",
        "入力層は７つのニューロンによって表される。 \n",
        "このとき、７つのニューロンはそれぞれ７つの単語に対応する。\n",
        "\n",
        "このように、単語をベクトルで表すことができれば、そのベクトルはニューラルネットワークを構成する様々な「レイヤ」によって処理できるようになる。\n",
        "\n",
        "たとえば、one-hot表現で表された単語を全結合層で変換する場合は、入力層のニューロンの重み付き和が中間層のニューロンとなる。\n",
        "\n",
        "本章では、全結合層はバイアスを用いない。\n",
        "\n",
        "全結合層による変換は、次のように書くことができる。"
      ],
      "metadata": {
        "id": "uVczrNYULtEG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N43_Ck3v-rxF",
        "outputId": "44f2e5e3-78c0-4549-baf9-6074bf0fda3c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[-1.00952946  0.27085363 -0.74458122]]\n"
          ]
        }
      ],
      "source": [
        "##全結合による変換\n",
        "import numpy as np \n",
        "c = np.array([[0, 1, 0, 0, 0, 0, 0]]) #入力\n",
        "W = np.random.randn(7, 3) #重み\n",
        "h = np.dot(c, W)  #中間ノード\n",
        "print(h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BesUaLcC9xGM"
      },
      "source": [
        "このコード例では、単語IDが1の単語をone-hot表現で表し、それを全結合層によって変換される例を示している。  \n",
        "全結合層の計算は行列の積によって行う。（本章ではバイアスは省略）  \n",
        "行列の積c*wを求めることは、重みの行ベクトルを\"抜き出す\"ことに相当する。\n",
        "\n",
        "MatMulレイヤでも同じことができる。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xvx8SEtj_P8u"
      },
      "outputs": [],
      "source": [
        "#バイアスを用いない全結合層のレイヤ\n",
        "class MatMul:\n",
        "    def __init__(self, W):\n",
        "        self.params = [W]\n",
        "        self.grads = [np.zeros_like(W)]\n",
        "        self.x = None\n",
        "\n",
        "    def forward(self, x):\n",
        "        W, = self.params\n",
        "        out = np.dot(x, W)\n",
        "        self.x = x\n",
        "        return out\n",
        "\n",
        "    def backward(self, dout):\n",
        "        W, = self.params\n",
        "        dx = np.dot(dout, W.T)\n",
        "        dW = np.dot(self.x.T, dout)\n",
        "        self.grads[0][...] = dW\n",
        "        return dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZpwIZzXS9sy-"
      },
      "source": [
        "MatMulレイヤに重みWを設定し、forward()メソッドによって順伝搬の処理を行う。  \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7AlPhLgN_vPS",
        "outputId": "0160bc97-9e51-4c3b-e122-c0c027c67c7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1.14764922 0.41950494 1.3480938 ]]\n"
          ]
        }
      ],
      "source": [
        "c = np.array([[1, 0, 0, 0, 0, 0, 0]]) \n",
        "W = np.random.randn(7, 3)\n",
        "layer = MatMul(W)\n",
        "h = layer.forward(c)\n",
        "print(h)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wYe84O_pLbBF"
      },
      "source": [
        "##3.2 シンプルなword2vec\n",
        "これで準備が整ったので、word2vecの実装に取りかかる。  \n",
        "\n",
        "これから行うことは、図3-3で示される「モデル」にニューラルネットワークを組み込むことである。 \n",
        "\n",
        "ここでは、そのニューラルネットワークに、word2vecで提案されている**continuous bag-of-words**(**CBOW**)と呼ばれるモデルを使う。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JewmDizwBI_j"
      },
      "source": [
        "###3.2.1 CBOWモデルの推論処理\n",
        "\n",
        "CBOWモデルは、コンテキストからターゲットを推測することを目的としたニューラルネットワークである。（「ターゲット」は中央の単語、その周囲の単語が「コンテキスト」）。  \n",
        "このCBOWモデルをできるだけ正確な推論ができるように訓練することで、単語の分散表現を獲得することができる。\n",
        "\n",
        "CBOWモデルへの入力はコンテキストである。このコンテキストは、['you', 'goodbye']のような単語のリストで表される。  \n",
        "それをone-hot表現に変換することで、CBOWモデルが処理できるように調整する。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8G7d8uygzQc"
      },
      "source": [
        "CBOWモデルの推論処理は、次のように実装できる。\n",
        "推論処理とは「スコア」を求める処理を指している。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7R0VjBHsCRX2",
        "outputId": "82ba87d8-790e-4afd-f937-37c25c66d3b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[ 0.04345703  0.13464149  0.20385304  0.84949028 -0.69599807 -0.11680884\n",
            "  -0.27993936]]\n"
          ]
        }
      ],
      "source": [
        "#CBOWの推論処理\n",
        "\n",
        "#サンプルのコンテキストデータ\n",
        "c0 = np.array([[1, 0, 0, 0, 0, 0, 0]])\n",
        "c1 = np.array([[0, 0, 1, 0, 0, 0, 0]])\n",
        "\n",
        "#重みの初期化\n",
        "W_in = np.random.randn(7, 3)\n",
        "W_out = np.random.randn(3, 7)\n",
        "\n",
        "#レイヤの生成\n",
        "in_layer0 = MatMul(W_in)\n",
        "in_layer1 = MatMul(W_in)\n",
        "out_layer = MatMul(W_out)\n",
        "\n",
        "#順伝播\n",
        "h0 = in_layer0.forward(c0)\n",
        "h1 = in_layer1.forward(c1)\n",
        "h = 0.5*(h0 + h1)\n",
        "s = out_layer.forward(h)\n",
        "\n",
        "print(s) #各単語のスコア（出現確率）"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CBOWモデルは最初に２つのMatMulレイヤがあり、その２つの出力を加算する。  \n",
        "その加算された値に0.5を乗算して平均が求められ、それが中間層のニューロンとなる。  \n",
        "最後に、中間層のニューロンに対して、別のMatMulレイヤが適用されスコアが出力される。  "
      ],
      "metadata": {
        "id": "3yYQahW7OdKu"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUtprRczLss-"
      },
      "source": [
        "###3.2.2 CBOWモデルの学習\n",
        "ここまで、説明したCBOWモデルは、出力層において各単語のスコアを出力した。  \n",
        "このスコアに対してSoftmax関数を適用することで、「確率」を得ることができる。  \n",
        "この確率は、コンテキスト（前後の単語）が与えれたときに、その中央にどの単語が出現するのかを表す。  \n",
        "\n",
        "この確率と教師ラベルから交差エントロピー誤差を求め、それを損失として学習を行う。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tidPsiyJLyjj"
      },
      "source": [
        "###3.2.3 word2vecの重みと分散表現\n",
        "これまで説明してきたように、word2vecで使用されるネットワークには２つの重みがある。  \n",
        "それは、入力側の全結合層の重み($W_{in}$）と、出力側の全結合層の重み($W_{out}$)である。  \n",
        "そして、入力側の重み$W_{in}$の各行が、各単語の分散表現に対応する。  \n",
        "さらに、出力側の重み$W_{out}$についても、単語の意味がエンコードされたベクトルが格納されていると考えられる。  \n",
        "\n",
        "word2vecに関して言えば、単語の分散表現は、「入力側の重みだけを利用する」というのがもっともポピュラーな選択肢である。  \n",
        "それにならい、$W_{in}$を単語の分散表現として利用する。\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjeA0sjeL9lu"
      },
      "source": [
        "##3.3 学習の準備"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ij01aGR_TsDP"
      },
      "source": [
        "###3.3.1 コンテキストとターゲット\n",
        "これからword2vecの学習を行うにあたって、まずは学習データの準備を行う。  \n",
        "ここでは、簡単な例として、これまでと同じく「You say goodbye and I say hello.」という一文をコーパスとして使う。 "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-fcM-JQMCAU"
      },
      "source": [
        "まずは、コーパスのテキストを単語IDに変換する。\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASbqLrVfLXD3"
      },
      "outputs": [],
      "source": [
        "def preprocess(text):\n",
        "  text = text.lower()\n",
        "  text = text.replace('.', ' .')\n",
        "  words = text.split(' ')\n",
        "\n",
        "  word_to_id = {}\n",
        "  id_to_word = {}\n",
        "  for word in words:\n",
        "    if word not in word_to_id:\n",
        "      new_id = len(word_to_id)\n",
        "      word_to_id[word] = new_id\n",
        "      id_to_word[new_id] = word\n",
        "  \n",
        "  corpus = np.array([word_to_id[w] for w in words])\n",
        "\n",
        "  return corpus, word_to_id, id_to_word"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nV3n21mVMRL1",
        "outputId": "20dc5429-4af5-4a7e-bc59-cdd2b45a6f78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 1 2 3 4 1 5 6]\n"
          ]
        }
      ],
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "print(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nyhgt40NKoQh",
        "outputId": "a4ece272-59ac-454d-80ba-350874e9261a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'you', 1: 'say', 2: 'goodbye', 3: 'and', 4: 'i', 5: 'hello', 6: '.'}\n"
          ]
        }
      ],
      "source": [
        "print(id_to_word)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Qqr2PNUK7i"
      },
      "source": [
        "単語IDの配列であるcorpusから、contextsとtargetを作る関数を実装する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rRPpJC58Xx-u"
      },
      "outputs": [],
      "source": [
        "def create_contexts_target(corpus, window_size=1):\n",
        "\n",
        "    # target は corpus の前後からwindow_sizeを引いたもの\n",
        "    target = corpus[window_size:-window_size]\n",
        "    contexts = []\n",
        "\n",
        "    # target の前後window_size分を contexts とする       \n",
        "    for idx in range(window_size, len(corpus)-window_size):  # idx = 1 〜 6\n",
        "        cs = []\n",
        "        for t in range(-window_size, window_size + 1):  # t = -1, 0, 1\n",
        "           if t == 0:\n",
        "                continue  # t = 0 のときは何もしない            \n",
        "           cs.append(corpus[idx + t])  # cs = courpus[idx-1, idx+1]\n",
        "        contexts.append(cs)\n",
        "    return np.array(contexts), np.array(target)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03Mik9e0Z1Ap"
      },
      "outputs": [],
      "source": [
        "contexts, target = create_contexts_target(corpus,window_size=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18EFaO5faCKu",
        "outputId": "8ea40582-cc3c-4f32-d965-c703f74e4bca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 2]\n",
            " [1 3]\n",
            " [2 4]\n",
            " [3 1]\n",
            " [4 5]\n",
            " [1 6]]\n"
          ]
        }
      ],
      "source": [
        "print(contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LVvQr3fBaC8g",
        "outputId": "47691d58-9b02-4a81-f817-fa2c5d1afd01"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 2 3 4 1 5]\n"
          ]
        }
      ],
      "source": [
        "print(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ov8Y5uoEBDMA"
      },
      "source": [
        "contextsの０次元目には各コンテキストデータが格納されている。  \n",
        "具体的にいうと、contexts[0]は０番目のコンテキスト、context[1]は1番目のコンテキスト・・・になる。  \n",
        "同様に、ターゲットについておm、target[0]は0番目のターゲット、target[1]は1番目のターゲット・・・と格納されている。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CugcFtKYaG9Y"
      },
      "source": [
        "これで、コーパスからコンテキストからターゲットを作ることができた。  \n",
        "###3.3.2 one-hot表現への変換\n",
        "続いてコンテキストからターゲットをone-hot表現に変換して、CBOWモデルに与えられる形にする。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBw-82CmaWIg"
      },
      "outputs": [],
      "source": [
        "def convert_one_hot(corpus, vocab_size):\n",
        "\n",
        "    N = corpus.shape[0]\n",
        "\n",
        "    if corpus.ndim == 1:  # 1次元の場合 (target の場合)\n",
        "        one_hot = np.zeros((N, vocab_size), dtype=np.int32)  # ゼロ行列作成\n",
        "        for idx, word_id in enumerate(corpus):  # targetからword_idへ順次代入\n",
        "            one_hot[idx, word_id] = 1\n",
        "\n",
        "    elif corpus.ndim == 2:  # 2次元の場合 (contexts の場合)\n",
        "        C = corpus.shape[1]\n",
        "        one_hot = np.zeros((N, C, vocab_size), dtype=np.int32)  # ゼロ行列作成\n",
        "        for idx_0, word_ids in enumerate(corpus):  # contextsからword_idsへ順次代入\n",
        "            for idx_1, word_id in enumerate(word_ids):  # word_idsからword_idへ順次代入\n",
        "                one_hot[idx_0, idx_1, word_id] = 1\n",
        "\n",
        "    return one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZZz3qWEPaF1l"
      },
      "outputs": [],
      "source": [
        "text = 'You say goodbye and I say hello.'\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "contexts, target = create_contexts_target(corpus, window_size=1)\n",
        "\n",
        "vocab_size = len(word_to_id)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPTUw2uSCuOu",
        "outputId": "3a263af6-3d81-4fdf-99b3-76fb489409ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[[1 0 0 0 0 0 0]\n",
            "  [0 0 1 0 0 0 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 1 0 0 0]]\n",
            "\n",
            " [[0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 1 0 0]]\n",
            "\n",
            " [[0 0 0 1 0 0 0]\n",
            "  [0 1 0 0 0 0 0]]\n",
            "\n",
            " [[0 0 0 0 1 0 0]\n",
            "  [0 0 0 0 0 1 0]]\n",
            "\n",
            " [[0 1 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 1]]]\n"
          ]
        }
      ],
      "source": [
        "print(contexts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjwZhcqECyvj",
        "outputId": "817a08d5-6d92-45ec-eb88-f58231fdc59c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0 1 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0]\n",
            " [0 0 0 1 0 0 0]\n",
            " [0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 0]\n",
            " [0 0 0 0 0 1 0]]\n"
          ]
        }
      ],
      "source": [
        "print(target)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "an0mMCicb15v"
      },
      "source": [
        "これで、学習データの準備が終わった。  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cmSV0U0Ib8Rw"
      },
      "source": [
        "###3.4 CBOWモデルの実装\n",
        "続いて、本題となるCBOWモデルの実装を行う。  \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8-mhcdnZcgl2"
      },
      "source": [
        "図3-19 CBOWモデルのネットワーク構成"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NU9G1pPzck32"
      },
      "source": [
        "図3-19のニューラルネットワークをSimpleCBOWという名前で実装する。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kBQRZr8mdHyQ"
      },
      "outputs": [],
      "source": [
        "# CBOWの実装\n",
        "class SimpleCBOW:\n",
        "    # 初期化メソッドの定義\n",
        "    def __init__(self, vocab_size, hidden_size):  #語彙数、中間層のニューロンの数\n",
        "        # ニューロン数を保存\n",
        "        V = vocab_size  # 入力層と出力層\n",
        "        H = hidden_size # 中間層\n",
        "        \n",
        "        # 重みの初期値を生成\n",
        "        W_in = 0.01 * np.random.randn(V, H).astype('f')\n",
        "        W_out = 0.01 * np.random.randn(H, V).astype('f')\n",
        "        \n",
        "        # レイヤを生成\n",
        "        self.in_layer0 = MatMul(W_in)  # 入力層\n",
        "        self.in_layer1 = MatMul(W_in)  # 入力層\n",
        "        self.out_layer = MatMul(W_out) # 出力層\n",
        "        self.loss_layer = SoftmaxWithLoss() # 損失層\n",
        "        \n",
        "        # 各レイヤをリストに格納\n",
        "        layers = [\n",
        "            self.in_layer0, \n",
        "            self.in_layer1, \n",
        "            self.out_layer, \n",
        "            self.loss_layer\n",
        "        ]\n",
        "        \n",
        "        # 各レイヤのパラメータと勾配をリストに格納\n",
        "        self.params = [] # パラメータ\n",
        "        self.grads = []  # 勾配\n",
        "        for layer in layers:\n",
        "            self.params += layer.params\n",
        "            self.grads += layer.grads\n",
        "        \n",
        "        # 単語の分散表現を保存\n",
        "        self.word_vecs = W_in\n",
        "    \n",
        "    # 順伝播メソッドの定義\n",
        "    def forward(self, contexts, target):\n",
        "        # 重み付き和を計算\n",
        "        h0 = self.in_layer0.forward(contexts[:, 0])\n",
        "        h1 = self.in_layer1.forward(contexts[:, 1])\n",
        "        h = (h0 + h1) * 0.5                            #平均をとって中間層のニューロンを求める。\n",
        "        \n",
        "        # スコアを計算\n",
        "        score = self.out_layer.forward(h)\n",
        "        \n",
        "        # 交差エントロピー誤差を計算\n",
        "        loss = self.loss_layer.forward(score, target)\n",
        "        return loss\n",
        "    \n",
        "    # 逆伝播メソッドの定義\n",
        "    def backward(self, dout=1):\n",
        "        # Lossレイヤの勾配を計算\n",
        "        ds = self.loss_layer.backward(dout)\n",
        "        \n",
        "        # 出力層の勾配を計算\n",
        "        da = self.out_layer.backward(ds)\n",
        "        da *= 0.5\n",
        "        \n",
        "        # 入力層の勾配を計算\n",
        "        self.in_layer1.backward(da)\n",
        "        self.in_layer0.backward(da)\n",
        "        return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jDUTsWX8dGmk"
      },
      "source": [
        "###3.4.1　学習コードの実装\n",
        "CBOWモデルの学習は通常のニューラルネットワークの学習とまったく同じである。  \n",
        "まずは学習データを準備して、ニューラルネットワークに与える。  \n",
        "そして勾配を求めて、重みパラメータを逐一アップデートする。  \n",
        "ここでは、その学習プロセスをTrainerクラスに行わせる。  \n",
        "それでは、学習のためのソースコードを示す。"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### softmaxの実装(Softmax-with-Lossレイヤ用)"
      ],
      "metadata": {
        "id": "k1L7VXBKPVfZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mWHlSsIWoI1Y"
      },
      "outputs": [],
      "source": [
        "def softmax(x):\n",
        "    if x.ndim == 2:\n",
        "        x = x - x.max(axis=1, keepdims=True)\n",
        "        x = np.exp(x)\n",
        "        x /= x.sum(axis=1, keepdims=True)\n",
        "    elif x.ndim == 1:\n",
        "        x = x - np.max(x)\n",
        "        x = np.exp(x) / np.sum(np.exp(x))\n",
        "\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### クロスエントロピー誤差の実装(Softmax-with-Lossレイヤ用)"
      ],
      "metadata": {
        "id": "c6EYR4zjPaKI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8bJg7BPyoQBr"
      },
      "outputs": [],
      "source": [
        "def cross_entropy_error(y, t):\n",
        "    if y.ndim == 1:\n",
        "        t = t.reshape(1, t.size)\n",
        "        y = y.reshape(1, y.size)\n",
        "        \n",
        "    # 教師データがone-hot-vectorの場合、正解ラベルのインデックスに変換\n",
        "    if t.size == y.size:\n",
        "        t = t.argmax(axis=1)\n",
        "             \n",
        "    batch_size = y.shape[0]\n",
        "\n",
        "    return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Softmax-with-Lossレイヤの実装"
      ],
      "metadata": {
        "id": "uO76-KALPd83"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PM00_98Ud-c2"
      },
      "outputs": [],
      "source": [
        "class SoftmaxWithLoss:\n",
        "    def __init__(self):\n",
        "        self.params, self.grads = [], []\n",
        "        self.y = None  # softmaxの出力\n",
        "        self.t = None  # 教師ラベル\n",
        "\n",
        "    def forward(self, x, t):\n",
        "        self.t = t\n",
        "        self.y = softmax(x)\n",
        "\n",
        "        # 教師ラベルがone-hotベクトルの場合、正解のインデックスに変換\n",
        "        if self.t.size == self.y.size:\n",
        "            self.t = self.t.argmax(axis=1)\n",
        "\n",
        "        loss = cross_entropy_error(self.y, self.t)\n",
        "        return loss\n",
        "\n",
        "    def backward(self, dout=1):\n",
        "        batch_size = self.t.shape[0]\n",
        "\n",
        "        dx = self.y.copy()\n",
        "        dx[np.arange(batch_size), self.t] -= 1\n",
        "        dx *= dout\n",
        "        dx = dx / batch_size\n",
        "\n",
        "        return dx\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainerクラスに必要"
      ],
      "metadata": {
        "id": "aqnF4luWPtUD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3PXrxMJ8uASe"
      },
      "outputs": [],
      "source": [
        "def remove_duplicate(params, grads):\n",
        "    '''\n",
        "    パラメータ配列中の重複する重みをひとつに集約し、\n",
        "    その重みに対応する勾配を加算する\n",
        "    '''\n",
        "    params, grads = params[:], grads[:]  # copy list\n",
        "\n",
        "    while True:\n",
        "        find_flg = False\n",
        "        L = len(params)\n",
        "\n",
        "        for i in range(0, L - 1):\n",
        "            for j in range(i + 1, L):\n",
        "                # 重みを共有する場合\n",
        "                if params[i] is params[j]:\n",
        "                    grads[i] += grads[j]  # 勾配の加算\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "                # 転置行列として重みを共有する場合（weight tying）\n",
        "                elif params[i].ndim == 2 and params[j].ndim == 2 and \\\n",
        "                     params[i].T.shape == params[j].shape and np.all(params[i].T == params[j]):\n",
        "                    grads[i] += grads[j].T\n",
        "                    find_flg = True\n",
        "                    params.pop(j)\n",
        "                    grads.pop(j)\n",
        "\n",
        "                if find_flg: break\n",
        "            if find_flg: break\n",
        "\n",
        "        if not find_flg: break\n",
        "\n",
        "    return params, grads"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trainerクラスに必要"
      ],
      "metadata": {
        "id": "Y7ICjxEtP_Td"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ-of6Ddssev"
      },
      "outputs": [],
      "source": [
        "def clip_grads(grads, max_norm):\n",
        "    total_norm = 0\n",
        "    for grad in grads:\n",
        "        total_norm += np.sum(grad ** 2)\n",
        "    total_norm = np.sqrt(total_norm)\n",
        "\n",
        "    rate = max_norm / (total_norm + 1e-6)\n",
        "    if rate < 1:\n",
        "        for grad in grads:\n",
        "            grad *= rate"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ニューラルネットワークの学習を行うTrainerクラス"
      ],
      "metadata": {
        "id": "LehGBAhFQCFv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O1-E4Vw_emur"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Trainer:\n",
        "    def __init__(self, model, optimizer):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.loss_list = []\n",
        "        self.eval_interval = None\n",
        "        self.current_epoch = 0\n",
        "\n",
        "    def fit(self, x, t, max_epoch=10, batch_size=32, max_grad=None, eval_interval=20):\n",
        "        data_size = len(x)\n",
        "        max_iters = data_size // batch_size\n",
        "        self.eval_interval = eval_interval\n",
        "        model, optimizer = self.model, self.optimizer\n",
        "        total_loss = 0\n",
        "        loss_count = 0\n",
        "\n",
        "        start_time = time.time()\n",
        "        for epoch in range(max_epoch):\n",
        "            # シャッフル\n",
        "            idx = numpy.random.permutation(numpy.arange(data_size))\n",
        "            x = x[idx]\n",
        "            t = t[idx]\n",
        "\n",
        "            for iters in range(max_iters):\n",
        "                batch_x = x[iters*batch_size:(iters+1)*batch_size]\n",
        "                batch_t = t[iters*batch_size:(iters+1)*batch_size]\n",
        "\n",
        "                # 勾配を求め、パラメータを更新\n",
        "                loss = model.forward(batch_x, batch_t)\n",
        "                model.backward()\n",
        "                params, grads = remove_duplicate(model.params, model.grads)  # 共有された重みを1つに集約\n",
        "                if max_grad is not None:\n",
        "                    clip_grads(grads, max_grad)\n",
        "                optimizer.update(params, grads)\n",
        "                total_loss += loss\n",
        "                loss_count += 1\n",
        "\n",
        "                # 評価\n",
        "                if (eval_interval is not None) and (iters % eval_interval) == 0:\n",
        "                    avg_loss = total_loss / loss_count\n",
        "                    elapsed_time = time.time() - start_time\n",
        "                    print('| epoch %d |  iter %d / %d | time %d[s] | loss %.2f'\n",
        "                          % (self.current_epoch + 1, iters + 1, max_iters, elapsed_time, avg_loss))\n",
        "                    self.loss_list.append(float(avg_loss))\n",
        "                    total_loss, loss_count = 0, 0\n",
        "\n",
        "            self.current_epoch += 1\n",
        "\n",
        "    def plot(self, ylim=None):\n",
        "        x = numpy.arange(len(self.loss_list))\n",
        "        if ylim is not None:\n",
        "            plt.ylim(*ylim)\n",
        "        plt.plot(x, self.loss_list, label='train')\n",
        "        plt.xlabel('iterations (x' + str(self.eval_interval) + ')')\n",
        "        plt.ylabel('loss')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### パラメータの更新を行うアルゴリズム"
      ],
      "metadata": {
        "id": "aWT7vUN1QEoE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2j6sPINoetRb"
      },
      "outputs": [],
      "source": [
        "class Adam:\n",
        "    '''\n",
        "    Adam (http://arxiv.org/abs/1412.6980v8)\n",
        "    '''\n",
        "    def __init__(self, lr=0.001, beta1=0.9, beta2=0.999):\n",
        "        self.lr = lr\n",
        "        self.beta1 = beta1\n",
        "        self.beta2 = beta2\n",
        "        self.iter = 0\n",
        "        self.m = None\n",
        "        self.v = None\n",
        "        \n",
        "    def update(self, params, grads):\n",
        "        if self.m is None:\n",
        "            self.m, self.v = [], []\n",
        "            for param in params:\n",
        "                self.m.append(np.zeros_like(param))\n",
        "                self.v.append(np.zeros_like(param))\n",
        "        \n",
        "        self.iter += 1\n",
        "        lr_t = self.lr * np.sqrt(1.0 - self.beta2**self.iter) / (1.0 - self.beta1**self.iter)\n",
        "\n",
        "        for i in range(len(params)):\n",
        "            self.m[i] += (1 - self.beta1) * (grads[i] - self.m[i])\n",
        "            self.v[i] += (1 - self.beta2) * (grads[i]**2 - self.v[i])\n",
        "            \n",
        "            params[i] -= lr_t * self.m[i] / (np.sqrt(self.v[i]) + 1e-7)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BrY4AYUvSVo"
      },
      "source": [
        "パラメータの更新を行う手法には、Adamを用いる。\n",
        "\n",
        "Trainerクラスは、ニューラルネットワークの学習を行ってくれる。  \n",
        "これは学習データからミニバッチを選び出し、それをニューラルネットワークに与えて勾配を求め、その勾配をOpitimizerに与えてパラメータの更新をするという一連の作業を行う。"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7q3zFtZ1eeTF",
        "outputId": "9164e1be-4f80-452e-9b3b-343d17fad594"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch 1 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 2 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 3 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 4 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 5 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 6 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 7 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 8 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 9 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 10 |  iter 1 / 2 | time 0[s] | loss 1.95\n",
            "| epoch 11 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 12 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 13 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 14 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 15 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 16 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 17 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 18 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 19 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 20 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 21 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 22 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 23 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 24 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 25 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 26 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 27 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 28 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 29 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 30 |  iter 1 / 2 | time 0[s] | loss 1.94\n",
            "| epoch 31 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 32 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 33 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 34 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 35 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 36 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 37 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 38 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 39 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 40 |  iter 1 / 2 | time 0[s] | loss 1.93\n",
            "| epoch 41 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 42 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 43 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 44 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 45 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 46 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 47 |  iter 1 / 2 | time 0[s] | loss 1.92\n",
            "| epoch 48 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 49 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 50 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 51 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 52 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 53 |  iter 1 / 2 | time 0[s] | loss 1.91\n",
            "| epoch 54 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 55 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 56 |  iter 1 / 2 | time 0[s] | loss 1.90\n",
            "| epoch 57 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 58 |  iter 1 / 2 | time 0[s] | loss 1.89\n",
            "| epoch 59 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 60 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 61 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 62 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 63 |  iter 1 / 2 | time 0[s] | loss 1.88\n",
            "| epoch 64 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 65 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 66 |  iter 1 / 2 | time 0[s] | loss 1.87\n",
            "| epoch 67 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 68 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 69 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 70 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 71 |  iter 1 / 2 | time 0[s] | loss 1.86\n",
            "| epoch 72 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 73 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 74 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 75 |  iter 1 / 2 | time 0[s] | loss 1.85\n",
            "| epoch 76 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 77 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 78 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 79 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 80 |  iter 1 / 2 | time 0[s] | loss 1.84\n",
            "| epoch 81 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 82 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 83 |  iter 1 / 2 | time 0[s] | loss 1.81\n",
            "| epoch 84 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 85 |  iter 1 / 2 | time 0[s] | loss 1.83\n",
            "| epoch 86 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 87 |  iter 1 / 2 | time 0[s] | loss 1.82\n",
            "| epoch 88 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 89 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 90 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 91 |  iter 1 / 2 | time 0[s] | loss 1.80\n",
            "| epoch 92 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 93 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 94 |  iter 1 / 2 | time 0[s] | loss 1.78\n",
            "| epoch 95 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 96 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
            "| epoch 97 |  iter 1 / 2 | time 0[s] | loss 1.79\n",
            "| epoch 98 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 99 |  iter 1 / 2 | time 0[s] | loss 1.77\n",
            "| epoch 100 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 101 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 102 |  iter 1 / 2 | time 0[s] | loss 1.75\n",
            "| epoch 103 |  iter 1 / 2 | time 0[s] | loss 1.76\n",
            "| epoch 104 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 105 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 106 |  iter 1 / 2 | time 0[s] | loss 1.74\n",
            "| epoch 107 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 108 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 109 |  iter 1 / 2 | time 0[s] | loss 1.72\n",
            "| epoch 110 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
            "| epoch 111 |  iter 1 / 2 | time 0[s] | loss 1.73\n",
            "| epoch 112 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 113 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
            "| epoch 114 |  iter 1 / 2 | time 0[s] | loss 1.71\n",
            "| epoch 115 |  iter 1 / 2 | time 0[s] | loss 1.67\n",
            "| epoch 116 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 117 |  iter 1 / 2 | time 0[s] | loss 1.70\n",
            "| epoch 118 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 119 |  iter 1 / 2 | time 0[s] | loss 1.65\n",
            "| epoch 120 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 121 |  iter 1 / 2 | time 0[s] | loss 1.66\n",
            "| epoch 122 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 123 |  iter 1 / 2 | time 0[s] | loss 1.68\n",
            "| epoch 124 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 125 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 126 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 127 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 128 |  iter 1 / 2 | time 0[s] | loss 1.60\n",
            "| epoch 129 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 130 |  iter 1 / 2 | time 0[s] | loss 1.64\n",
            "| epoch 131 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 132 |  iter 1 / 2 | time 0[s] | loss 1.63\n",
            "| epoch 133 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 134 |  iter 1 / 2 | time 0[s] | loss 1.61\n",
            "| epoch 135 |  iter 1 / 2 | time 0[s] | loss 1.58\n",
            "| epoch 136 |  iter 1 / 2 | time 0[s] | loss 1.59\n",
            "| epoch 137 |  iter 1 / 2 | time 0[s] | loss 1.62\n",
            "| epoch 138 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 139 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 140 |  iter 1 / 2 | time 0[s] | loss 1.57\n",
            "| epoch 141 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 142 |  iter 1 / 2 | time 0[s] | loss 1.58\n",
            "| epoch 143 |  iter 1 / 2 | time 0[s] | loss 1.58\n",
            "| epoch 144 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
            "| epoch 145 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 146 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 147 |  iter 1 / 2 | time 0[s] | loss 1.54\n",
            "| epoch 148 |  iter 1 / 2 | time 0[s] | loss 1.56\n",
            "| epoch 149 |  iter 1 / 2 | time 0[s] | loss 1.49\n",
            "| epoch 150 |  iter 1 / 2 | time 0[s] | loss 1.52\n",
            "| epoch 151 |  iter 1 / 2 | time 0[s] | loss 1.50\n",
            "| epoch 152 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 153 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 154 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
            "| epoch 155 |  iter 1 / 2 | time 0[s] | loss 1.53\n",
            "| epoch 156 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 157 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 158 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 159 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 160 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 161 |  iter 1 / 2 | time 0[s] | loss 1.51\n",
            "| epoch 162 |  iter 1 / 2 | time 0[s] | loss 1.47\n",
            "| epoch 163 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 164 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 165 |  iter 1 / 2 | time 0[s] | loss 1.48\n",
            "| epoch 166 |  iter 1 / 2 | time 0[s] | loss 1.44\n",
            "| epoch 167 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 168 |  iter 1 / 2 | time 0[s] | loss 1.43\n",
            "| epoch 169 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
            "| epoch 170 |  iter 1 / 2 | time 0[s] | loss 1.45\n",
            "| epoch 171 |  iter 1 / 2 | time 0[s] | loss 1.46\n",
            "| epoch 172 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 173 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 174 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 175 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 176 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 177 |  iter 1 / 2 | time 0[s] | loss 1.42\n",
            "| epoch 178 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 179 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 180 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 181 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 182 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 183 |  iter 1 / 2 | time 0[s] | loss 1.41\n",
            "| epoch 184 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 185 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 186 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 187 |  iter 1 / 2 | time 0[s] | loss 1.28\n",
            "| epoch 188 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 189 |  iter 1 / 2 | time 0[s] | loss 1.40\n",
            "| epoch 190 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 191 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 192 |  iter 1 / 2 | time 0[s] | loss 1.25\n",
            "| epoch 193 |  iter 1 / 2 | time 0[s] | loss 1.35\n",
            "| epoch 194 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 195 |  iter 1 / 2 | time 0[s] | loss 1.36\n",
            "| epoch 196 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 197 |  iter 1 / 2 | time 0[s] | loss 1.39\n",
            "| epoch 198 |  iter 1 / 2 | time 0[s] | loss 1.24\n",
            "| epoch 199 |  iter 1 / 2 | time 0[s] | loss 1.31\n",
            "| epoch 200 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 201 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 202 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 203 |  iter 1 / 2 | time 0[s] | loss 1.32\n",
            "| epoch 204 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 205 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 206 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 207 |  iter 1 / 2 | time 0[s] | loss 1.38\n",
            "| epoch 208 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 209 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 210 |  iter 1 / 2 | time 0[s] | loss 1.30\n",
            "| epoch 211 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 212 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 213 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 214 |  iter 1 / 2 | time 0[s] | loss 1.33\n",
            "| epoch 215 |  iter 1 / 2 | time 0[s] | loss 1.22\n",
            "| epoch 216 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 217 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 218 |  iter 1 / 2 | time 0[s] | loss 1.21\n",
            "| epoch 219 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
            "| epoch 220 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 221 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
            "| epoch 222 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 223 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 224 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 225 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 226 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 227 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 228 |  iter 1 / 2 | time 0[s] | loss 1.29\n",
            "| epoch 229 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 230 |  iter 1 / 2 | time 0[s] | loss 1.26\n",
            "| epoch 231 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 232 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 233 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 234 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 235 |  iter 1 / 2 | time 0[s] | loss 1.17\n",
            "| epoch 236 |  iter 1 / 2 | time 0[s] | loss 1.15\n",
            "| epoch 237 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 238 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 239 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 240 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 241 |  iter 1 / 2 | time 0[s] | loss 1.20\n",
            "| epoch 242 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 243 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 244 |  iter 1 / 2 | time 0[s] | loss 1.10\n",
            "| epoch 245 |  iter 1 / 2 | time 0[s] | loss 1.12\n",
            "| epoch 246 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 247 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 248 |  iter 1 / 2 | time 0[s] | loss 1.08\n",
            "| epoch 249 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 250 |  iter 1 / 2 | time 0[s] | loss 1.11\n",
            "| epoch 251 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 252 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 253 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 254 |  iter 1 / 2 | time 0[s] | loss 1.16\n",
            "| epoch 255 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 256 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 257 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 258 |  iter 1 / 2 | time 0[s] | loss 1.23\n",
            "| epoch 259 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 260 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 261 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 262 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 263 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 264 |  iter 1 / 2 | time 0[s] | loss 1.13\n",
            "| epoch 265 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 266 |  iter 1 / 2 | time 0[s] | loss 1.06\n",
            "| epoch 267 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 268 |  iter 1 / 2 | time 0[s] | loss 1.01\n",
            "| epoch 269 |  iter 1 / 2 | time 0[s] | loss 1.19\n",
            "| epoch 270 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 271 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 272 |  iter 1 / 2 | time 0[s] | loss 1.18\n",
            "| epoch 273 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 274 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 275 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 276 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 277 |  iter 1 / 2 | time 0[s] | loss 1.07\n",
            "| epoch 278 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 279 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 280 |  iter 1 / 2 | time 0[s] | loss 0.99\n",
            "| epoch 281 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 282 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 283 |  iter 1 / 2 | time 0[s] | loss 0.93\n",
            "| epoch 284 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 285 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 286 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 287 |  iter 1 / 2 | time 0[s] | loss 1.00\n",
            "| epoch 288 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 289 |  iter 1 / 2 | time 0[s] | loss 1.03\n",
            "| epoch 290 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 291 |  iter 1 / 2 | time 0[s] | loss 1.14\n",
            "| epoch 292 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 293 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 294 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 295 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 296 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 297 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 298 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 299 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 300 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 301 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 302 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 303 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 304 |  iter 1 / 2 | time 0[s] | loss 1.02\n",
            "| epoch 305 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 306 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 307 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 308 |  iter 1 / 2 | time 0[s] | loss 1.05\n",
            "| epoch 309 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 310 |  iter 1 / 2 | time 0[s] | loss 0.88\n",
            "| epoch 311 |  iter 1 / 2 | time 0[s] | loss 0.98\n",
            "| epoch 312 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 313 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 314 |  iter 1 / 2 | time 0[s] | loss 1.04\n",
            "| epoch 315 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 316 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 317 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 318 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 319 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 320 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 321 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 322 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 323 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 324 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 325 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 326 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 327 |  iter 1 / 2 | time 0[s] | loss 0.92\n",
            "| epoch 328 |  iter 1 / 2 | time 0[s] | loss 0.97\n",
            "| epoch 329 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 330 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 331 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 332 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 333 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 334 |  iter 1 / 2 | time 0[s] | loss 0.89\n",
            "| epoch 335 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 336 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 337 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 338 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 339 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 340 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 341 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 342 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 343 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 344 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 345 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 346 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 347 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 348 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 349 |  iter 1 / 2 | time 0[s] | loss 0.94\n",
            "| epoch 350 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 351 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 352 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 353 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 354 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 355 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 356 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 357 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 358 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 359 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 360 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 361 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 362 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 363 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 364 |  iter 1 / 2 | time 0[s] | loss 0.96\n",
            "| epoch 365 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 366 |  iter 1 / 2 | time 0[s] | loss 0.87\n",
            "| epoch 367 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 368 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 369 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 370 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 371 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 372 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 373 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 374 |  iter 1 / 2 | time 0[s] | loss 0.86\n",
            "| epoch 375 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 376 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 377 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 378 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 379 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 380 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 381 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 382 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 383 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 384 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 385 |  iter 1 / 2 | time 0[s] | loss 0.90\n",
            "| epoch 386 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 387 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 388 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 389 |  iter 1 / 2 | time 0[s] | loss 0.95\n",
            "| epoch 390 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 391 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 392 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 393 |  iter 1 / 2 | time 0[s] | loss 0.83\n",
            "| epoch 394 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 395 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 396 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 397 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 398 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 399 |  iter 1 / 2 | time 0[s] | loss 0.91\n",
            "| epoch 400 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 401 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 402 |  iter 1 / 2 | time 0[s] | loss 0.84\n",
            "| epoch 403 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 404 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 405 |  iter 1 / 2 | time 0[s] | loss 0.78\n",
            "| epoch 406 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 407 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 408 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 409 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 410 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 411 |  iter 1 / 2 | time 0[s] | loss 0.82\n",
            "| epoch 412 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 413 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 414 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 415 |  iter 1 / 2 | time 0[s] | loss 0.80\n",
            "| epoch 416 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 417 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 418 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 419 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 420 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 421 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 422 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 423 |  iter 1 / 2 | time 0[s] | loss 0.81\n",
            "| epoch 424 |  iter 1 / 2 | time 0[s] | loss 0.76\n",
            "| epoch 425 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 426 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 427 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 428 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 429 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 430 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 431 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 432 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 433 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 434 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 435 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 436 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 437 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 438 |  iter 1 / 2 | time 0[s] | loss 0.85\n",
            "| epoch 439 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 440 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 441 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 442 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 443 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 444 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 445 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 446 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 447 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 448 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 449 |  iter 1 / 2 | time 0[s] | loss 0.74\n",
            "| epoch 450 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 451 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 452 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 453 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 454 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 455 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 456 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 457 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 458 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 459 |  iter 1 / 2 | time 0[s] | loss 0.75\n",
            "| epoch 460 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 461 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 462 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 463 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 464 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 465 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 466 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 467 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 468 |  iter 1 / 2 | time 0[s] | loss 0.73\n",
            "| epoch 469 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 470 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 471 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 472 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 473 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 474 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 475 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 476 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 477 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 478 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 479 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 480 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 481 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 482 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 483 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 484 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 485 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 486 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 487 |  iter 1 / 2 | time 0[s] | loss 0.79\n",
            "| epoch 488 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 489 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 490 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 491 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 492 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 493 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 494 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 495 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 496 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 497 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 498 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 499 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 500 |  iter 1 / 2 | time 0[s] | loss 0.77\n",
            "| epoch 501 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 502 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 503 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 504 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 505 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 506 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 507 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 508 |  iter 1 / 2 | time 0[s] | loss 0.67\n",
            "| epoch 509 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 510 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 511 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 512 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 513 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 514 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 515 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 516 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 517 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 518 |  iter 1 / 2 | time 0[s] | loss 0.66\n",
            "| epoch 519 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 520 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 521 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 522 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 523 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 524 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 525 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 526 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 527 |  iter 1 / 2 | time 0[s] | loss 0.65\n",
            "| epoch 528 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 529 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 530 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 531 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 532 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 533 |  iter 1 / 2 | time 0[s] | loss 0.64\n",
            "| epoch 534 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 535 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 536 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 537 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 538 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 539 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 540 |  iter 1 / 2 | time 0[s] | loss 0.63\n",
            "| epoch 541 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 542 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 543 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 544 |  iter 1 / 2 | time 0[s] | loss 0.72\n",
            "| epoch 545 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 546 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 547 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 548 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 549 |  iter 1 / 2 | time 0[s] | loss 0.71\n",
            "| epoch 550 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 551 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 552 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 553 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 554 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 555 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 556 |  iter 1 / 2 | time 0[s] | loss 0.70\n",
            "| epoch 557 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 558 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 559 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 560 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 561 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 562 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 563 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 564 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 565 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 566 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 567 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 568 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 569 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 570 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 571 |  iter 1 / 2 | time 0[s] | loss 0.68\n",
            "| epoch 572 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 573 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 574 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 575 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 576 |  iter 1 / 2 | time 0[s] | loss 0.60\n",
            "| epoch 577 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 578 |  iter 1 / 2 | time 0[s] | loss 0.69\n",
            "| epoch 579 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 580 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 581 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 582 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 583 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 584 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 585 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 586 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 587 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 588 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 589 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 590 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 591 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 592 |  iter 1 / 2 | time 0[s] | loss 0.61\n",
            "| epoch 593 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 594 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 595 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 596 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 597 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 598 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 599 |  iter 1 / 2 | time 0[s] | loss 0.58\n",
            "| epoch 600 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 601 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 602 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 603 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 604 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 605 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 606 |  iter 1 / 2 | time 0[s] | loss 0.57\n",
            "| epoch 607 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 608 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 609 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 610 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 611 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 612 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 613 |  iter 1 / 2 | time 0[s] | loss 0.56\n",
            "| epoch 614 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 615 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 616 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 617 |  iter 1 / 2 | time 0[s] | loss 0.59\n",
            "| epoch 618 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 619 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 620 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 621 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 622 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 623 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 624 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 625 |  iter 1 / 2 | time 0[s] | loss 0.55\n",
            "| epoch 626 |  iter 1 / 2 | time 0[s] | loss 0.20\n",
            "| epoch 627 |  iter 1 / 2 | time 0[s] | loss 0.62\n",
            "| epoch 628 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 629 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 630 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 631 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 632 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 633 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 634 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 635 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 636 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 637 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 638 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 639 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 640 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 641 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 642 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 643 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 644 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 645 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 646 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 647 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 648 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 649 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 650 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 651 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 652 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 653 |  iter 1 / 2 | time 0[s] | loss 0.44\n",
            "| epoch 654 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 655 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 656 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 657 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 658 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 659 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 660 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 661 |  iter 1 / 2 | time 0[s] | loss 0.53\n",
            "| epoch 662 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 663 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 664 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 665 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 666 |  iter 1 / 2 | time 0[s] | loss 0.43\n",
            "| epoch 667 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 668 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 669 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 670 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 671 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 672 |  iter 1 / 2 | time 0[s] | loss 0.48\n",
            "| epoch 673 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 674 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 675 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 676 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 677 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 678 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 679 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 680 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
            "| epoch 681 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 682 |  iter 1 / 2 | time 0[s] | loss 0.52\n",
            "| epoch 683 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 684 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 685 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 686 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 687 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 688 |  iter 1 / 2 | time 0[s] | loss 0.47\n",
            "| epoch 689 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
            "| epoch 690 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 691 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 692 |  iter 1 / 2 | time 0[s] | loss 0.51\n",
            "| epoch 693 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 694 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 695 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 696 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 697 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 698 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 699 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 700 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 701 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 702 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 703 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 704 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 705 |  iter 1 / 2 | time 0[s] | loss 0.33\n",
            "| epoch 706 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 707 |  iter 1 / 2 | time 0[s] | loss 0.46\n",
            "| epoch 708 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 709 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 710 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 711 |  iter 1 / 2 | time 0[s] | loss 0.30\n",
            "| epoch 712 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 713 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 714 |  iter 1 / 2 | time 0[s] | loss 0.40\n",
            "| epoch 715 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 716 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 717 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
            "| epoch 718 |  iter 1 / 2 | time 0[s] | loss 0.50\n",
            "| epoch 719 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 720 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 721 |  iter 1 / 2 | time 0[s] | loss 0.36\n",
            "| epoch 722 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 723 |  iter 1 / 2 | time 0[s] | loss 0.29\n",
            "| epoch 724 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 725 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 726 |  iter 1 / 2 | time 0[s] | loss 0.39\n",
            "| epoch 727 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 728 |  iter 1 / 2 | time 0[s] | loss 0.24\n",
            "| epoch 729 |  iter 1 / 2 | time 0[s] | loss 0.49\n",
            "| epoch 730 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
            "| epoch 731 |  iter 1 / 2 | time 0[s] | loss 0.35\n",
            "| epoch 732 |  iter 1 / 2 | time 0[s] | loss 0.32\n",
            "| epoch 733 |  iter 1 / 2 | time 0[s] | loss 0.54\n",
            "| epoch 734 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
            "| epoch 735 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
            "| epoch 736 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 737 |  iter 1 / 2 | time 0[s] | loss 0.42\n",
            "| epoch 738 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 739 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 740 |  iter 1 / 2 | time 0[s] | loss 0.45\n",
            "| epoch 741 |  iter 1 / 2 | time 0[s] | loss 0.41\n",
            "| epoch 742 |  iter 1 / 2 | time 0[s] | loss 0.28\n",
            "| epoch 743 |  iter 1 / 2 | time 0[s] | loss 0.38\n",
            "| epoch 744 |  iter 1 / 2 | time 0[s] | loss 0.37\n",
            "| epoch 745 |  iter 1 / 2 | time 0[s] | loss 0.34\n",
            "| epoch 746 |  iter 1 / 2 | time 0[s] | loss 0.31\n",
            "| epoch 747 |  iter 1 / 2 | time 1[s] | loss 0.48\n",
            "| epoch 748 |  iter 1 / 2 | time 1[s] | loss 0.27\n",
            "| epoch 749 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 750 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 751 |  iter 1 / 2 | time 1[s] | loss 0.48\n",
            "| epoch 752 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 753 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 754 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 755 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 756 |  iter 1 / 2 | time 1[s] | loss 0.47\n",
            "| epoch 757 |  iter 1 / 2 | time 1[s] | loss 0.37\n",
            "| epoch 758 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 759 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 760 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 761 |  iter 1 / 2 | time 1[s] | loss 0.37\n",
            "| epoch 762 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 763 |  iter 1 / 2 | time 1[s] | loss 0.37\n",
            "| epoch 764 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 765 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 766 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 767 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 768 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 769 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 770 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 771 |  iter 1 / 2 | time 1[s] | loss 0.46\n",
            "| epoch 772 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 773 |  iter 1 / 2 | time 1[s] | loss 0.54\n",
            "| epoch 774 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 775 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 776 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 777 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 778 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 779 |  iter 1 / 2 | time 1[s] | loss 0.18\n",
            "| epoch 780 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 781 |  iter 1 / 2 | time 1[s] | loss 0.38\n",
            "| epoch 782 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 783 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 784 |  iter 1 / 2 | time 1[s] | loss 0.25\n",
            "| epoch 785 |  iter 1 / 2 | time 1[s] | loss 0.46\n",
            "| epoch 786 |  iter 1 / 2 | time 1[s] | loss 0.25\n",
            "| epoch 787 |  iter 1 / 2 | time 1[s] | loss 0.46\n",
            "| epoch 788 |  iter 1 / 2 | time 1[s] | loss 0.27\n",
            "| epoch 789 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 790 |  iter 1 / 2 | time 1[s] | loss 0.38\n",
            "| epoch 791 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 792 |  iter 1 / 2 | time 1[s] | loss 0.49\n",
            "| epoch 793 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 794 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 795 |  iter 1 / 2 | time 1[s] | loss 0.38\n",
            "| epoch 796 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 797 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 798 |  iter 1 / 2 | time 1[s] | loss 0.25\n",
            "| epoch 799 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 800 |  iter 1 / 2 | time 1[s] | loss 0.45\n",
            "| epoch 801 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 802 |  iter 1 / 2 | time 1[s] | loss 0.38\n",
            "| epoch 803 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 804 |  iter 1 / 2 | time 1[s] | loss 0.38\n",
            "| epoch 805 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 806 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 807 |  iter 1 / 2 | time 1[s] | loss 0.27\n",
            "| epoch 808 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 809 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 810 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 811 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 812 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 813 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 814 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 815 |  iter 1 / 2 | time 1[s] | loss 0.53\n",
            "| epoch 816 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 817 |  iter 1 / 2 | time 1[s] | loss 0.37\n",
            "| epoch 818 |  iter 1 / 2 | time 1[s] | loss 0.45\n",
            "| epoch 819 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 820 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 821 |  iter 1 / 2 | time 1[s] | loss 0.13\n",
            "| epoch 822 |  iter 1 / 2 | time 1[s] | loss 0.47\n",
            "| epoch 823 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 824 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 825 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 826 |  iter 1 / 2 | time 1[s] | loss 0.52\n",
            "| epoch 827 |  iter 1 / 2 | time 1[s] | loss 0.26\n",
            "| epoch 828 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 829 |  iter 1 / 2 | time 1[s] | loss 0.45\n",
            "| epoch 830 |  iter 1 / 2 | time 1[s] | loss 0.23\n",
            "| epoch 831 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 832 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 833 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 834 |  iter 1 / 2 | time 1[s] | loss 0.15\n",
            "| epoch 835 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 836 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 837 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 838 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 839 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 840 |  iter 1 / 2 | time 1[s] | loss 0.36\n",
            "| epoch 841 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 842 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 843 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 844 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 845 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 846 |  iter 1 / 2 | time 1[s] | loss 0.12\n",
            "| epoch 847 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 848 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 849 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 850 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 851 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 852 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 853 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 854 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 855 |  iter 1 / 2 | time 1[s] | loss 0.13\n",
            "| epoch 856 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 857 |  iter 1 / 2 | time 1[s] | loss 0.24\n",
            "| epoch 858 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 859 |  iter 1 / 2 | time 1[s] | loss 0.35\n",
            "| epoch 860 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 861 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 862 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 863 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 864 |  iter 1 / 2 | time 1[s] | loss 0.45\n",
            "| epoch 865 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 866 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 867 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 868 |  iter 1 / 2 | time 1[s] | loss 0.54\n",
            "| epoch 869 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 870 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 871 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 872 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 873 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 874 |  iter 1 / 2 | time 1[s] | loss 0.23\n",
            "| epoch 875 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 876 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 877 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 878 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 879 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 880 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 881 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 882 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 883 |  iter 1 / 2 | time 1[s] | loss 0.08\n",
            "| epoch 884 |  iter 1 / 2 | time 1[s] | loss 0.45\n",
            "| epoch 885 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 886 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 887 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 888 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 889 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 890 |  iter 1 / 2 | time 1[s] | loss 0.34\n",
            "| epoch 891 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 892 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 893 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 894 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 895 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 896 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 897 |  iter 1 / 2 | time 1[s] | loss 0.53\n",
            "| epoch 898 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 899 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 900 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 901 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 902 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 903 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 904 |  iter 1 / 2 | time 1[s] | loss 0.44\n",
            "| epoch 905 |  iter 1 / 2 | time 1[s] | loss 0.08\n",
            "| epoch 906 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 907 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 908 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 909 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 910 |  iter 1 / 2 | time 1[s] | loss 0.52\n",
            "| epoch 911 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 912 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 913 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 914 |  iter 1 / 2 | time 1[s] | loss 0.22\n",
            "| epoch 915 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 916 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 917 |  iter 1 / 2 | time 1[s] | loss 0.11\n",
            "| epoch 918 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 919 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 920 |  iter 1 / 2 | time 1[s] | loss 0.33\n",
            "| epoch 921 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 922 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 923 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 924 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 925 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 926 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 927 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 928 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 929 |  iter 1 / 2 | time 1[s] | loss 0.42\n",
            "| epoch 930 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 931 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 932 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 933 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 934 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 935 |  iter 1 / 2 | time 1[s] | loss 0.43\n",
            "| epoch 936 |  iter 1 / 2 | time 1[s] | loss 0.18\n",
            "| epoch 937 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 938 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 939 |  iter 1 / 2 | time 1[s] | loss 0.21\n",
            "| epoch 940 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 941 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 942 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 943 |  iter 1 / 2 | time 1[s] | loss 0.18\n",
            "| epoch 944 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 945 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 946 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 947 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 948 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 949 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 950 |  iter 1 / 2 | time 1[s] | loss 0.32\n",
            "| epoch 951 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 952 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 953 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 954 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 955 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 956 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 957 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 958 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 959 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 960 |  iter 1 / 2 | time 1[s] | loss 0.08\n",
            "| epoch 961 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 962 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 963 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 964 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 965 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 966 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 967 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 968 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 969 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 970 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 971 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 972 |  iter 1 / 2 | time 1[s] | loss 0.31\n",
            "| epoch 973 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 974 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 975 |  iter 1 / 2 | time 1[s] | loss 0.09\n",
            "| epoch 976 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 977 |  iter 1 / 2 | time 1[s] | loss 0.51\n",
            "| epoch 978 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 979 |  iter 1 / 2 | time 1[s] | loss 0.28\n",
            "| epoch 980 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 981 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 982 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 983 |  iter 1 / 2 | time 1[s] | loss 0.20\n",
            "| epoch 984 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 985 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 986 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 987 |  iter 1 / 2 | time 1[s] | loss 0.19\n",
            "| epoch 988 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 989 |  iter 1 / 2 | time 1[s] | loss 0.18\n",
            "| epoch 990 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 991 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 992 |  iter 1 / 2 | time 1[s] | loss 0.07\n",
            "| epoch 993 |  iter 1 / 2 | time 1[s] | loss 0.41\n",
            "| epoch 994 |  iter 1 / 2 | time 1[s] | loss 0.18\n",
            "| epoch 995 |  iter 1 / 2 | time 1[s] | loss 0.40\n",
            "| epoch 996 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 997 |  iter 1 / 2 | time 1[s] | loss 0.39\n",
            "| epoch 998 |  iter 1 / 2 | time 1[s] | loss 0.29\n",
            "| epoch 999 |  iter 1 / 2 | time 1[s] | loss 0.30\n",
            "| epoch 1000 |  iter 1 / 2 | time 1[s] | loss 0.18\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "aaaa\n"
          ]
        }
      ],
      "source": [
        "window_size = 1\n",
        "hidden_size = 5 \n",
        "batch_size = 3\n",
        "max_epoch = 1000\n",
        "\n",
        "#学習データの準備\n",
        "text = 'You say goodbye and I say hello.'   \n",
        "\n",
        "#学習データの前処理\n",
        "corpus, word_to_id, id_to_word = preprocess(text)\n",
        "\n",
        "#学習データのone-hot表現化\n",
        "vocab_size = len(word_to_id)\n",
        "contexts, target = create_contexts_target(corpus, window_size)\n",
        "target = convert_one_hot(target, vocab_size)\n",
        "contexts = convert_one_hot(contexts, vocab_size)\n",
        "\n",
        "#学習\n",
        "model = SimpleCBOW(vocab_size, hidden_size)\n",
        "optimizer = Adam()\n",
        "trainer = Trainer(model, optimizer)\n",
        "\n",
        "trainer.fit(contexts, target, max_epoch, batch_size)\n",
        "trainer.plot()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U78NVZETvMum"
      },
      "source": [
        "上の図は、学習の経過をグラフで表示したものである。\n",
        "横軸は学習の回数、縦軸は損失を表している。  \n",
        "\n",
        "学習回数を重ねるごとに、損失が減少していることがわかる。  \n",
        "うまく学習できているようである。  \n",
        "\n",
        "それでは、学習が終わった後の重みパラメータを見ていきたい。  \n",
        "ここでは、入力側のMatMulレイヤの重みを取り出し、実際に中身を確認してみることにする。  \n",
        "なお、入力側のMatMulレイヤの重みはメンバ変数のword_vecsに設定されている。\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "6z2EeGnLwY6G",
        "outputId": "54e35b50-da35-4ddc-87ee-3b51fce80e7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "you [-0.85849947 -0.92845005  0.899041   -0.9200242  -1.7018394 ]\n",
            "say [ 1.1433655  0.8794653 -1.170082   1.1800435 -1.2999091]\n",
            "goodbye [-1.0805677  -1.020402    0.99637717 -0.99217117  0.04992517]\n",
            "and [ 0.67271984  1.8690711  -0.1597391   0.6694496  -1.5470127 ]\n",
            "i [-1.055842   -1.0267671   1.0070229  -0.9825193   0.05926484]\n",
            "hello [-0.88861626 -0.9288655   0.9045676  -0.89443624 -1.7150296 ]\n",
            ". [ 1.3193552 -0.9588528 -1.6636506  1.3852448 -0.243235 ]\n"
          ]
        }
      ],
      "source": [
        "word_vecs = model.word_vecs\n",
        "for word_id, word in id_to_word.items():\n",
        "    print(word, word_vecs[word_id])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YiH2Yxmzw4dY"
      },
      "source": [
        "word_vecsという名前で重みを取り出すと、各行に対応する単語IDの分散表現が格納されている。  \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ysIQKVw6yk2y"
      },
      "source": [
        "これで、単語を密なベクトルで表すことができた。  \n",
        "これが単語の分散表現である。  \n",
        "この分散表現は、「単語の意味」をうまく捉えたベクトル表現になっていることが期待できる。  \n",
        "\n",
        "しかし残念ながら、ここで扱ったコーパスは、あまりにもサイズが小さいので良い結果が得られない。  \n",
        "実際、コーパスを大きく実用的なものに変換すれば、良い結果が得られるだろう。  \n",
        "\n",
        "しかし、その場合は処理速度の点で問題が発生する。  \n",
        "というのも、現段階でのCBOWモデルの実装は処理効率の点でいくつか課題を抱えている。  \n",
        "\n",
        "次章では現状の\"シンプル\"なCBOWモデルに対して改良を加え、\"本物\"のCBOWモデルを実装する。"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": [],
      "authorship_tag": "ABX9TyMszb730tUsVa/FdLpZkVfw",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}